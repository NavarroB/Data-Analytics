{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis with Scikit Learn\n",
    "\n",
    "Please import the necessary libraries. It is good practice to do that at the beginning of your coding. In case you find out that you need more imports, you can add them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Loading the data\n",
    "\n",
    "We will analyse the Titanic dataset. A training and a testing dataset can be found in \"data/titanic_kaggle\" as train.csv and test.csv. \n",
    "\n",
    "Use pandas.read_csv() to import train.csv and assign it to the variable df_train. Use pandas.read_csv() to import test.csv and assign it to the variable df_test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use DataFrame.shape to calculate the number of rows and columns in df_train. How many instances (rows) does the dataset have? How many attributes are included? How many attributes are included in the test dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the descriptions of the different attributes provided by the data dictionary contained with the dataset. \n",
    "- PassengerID - A column added by Kaggle to identify each row and make submissions easier\n",
    "- Survived - Whether the passenger survived or not and the value we are predicting (0=No, 1=Yes)\n",
    "- Pclass - The class of the ticket the passenger purchased (1=1st, 2=2nd, 3=3rd)\n",
    "- Sex - The passenger's sex\n",
    "- Age - The passenger's age in years\n",
    "- SibSp - The number of siblings or spouses the passenger had aboard the Titanic\n",
    "- Parch - The number of parents or children the passenger had aboard the Titanic\n",
    "- Ticket - The passenger's ticket number\n",
    "- Fare - The fare the passenger paid\n",
    "- Cabin - The passenger's cabin number\n",
    "- Embarked - The port where the passenger embarked (C=Cherbourg, Q=Queenstown, S=Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get a view on the actual data. How do the first five instances of the training data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any machine learning exercise, thinking about the topic you are predicting is very important. We call this step acquiring domain knowledge, and it's one of the most important determinants for success in machine learning.\n",
    "\n",
    "In this case, understanding the Titanic disaster and specifically what variables might affect the outcome of survival is important. Anyone who has watched the movie Titanic would remember that women and children were given preference to lifeboats (as they were in real life). You would also remember the vast class disparity of the passengers.\n",
    "\n",
    "This indicates that Age, Sex, and PClass may be good predictors of survival. We'll start by exploring Sex and Pclass by visualizing the data. \n",
    "\n",
    "How many female and how many male passengers survived?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In which passenger class did most of the people survive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Transforming the data\n",
    "\n",
    "Which attributes do you want to keep for your classification? Which attributes do you need to transform? \n",
    "\n",
    "Use the `info` method to get an overview of the attributes for the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the attributes which are not numeric and you want to keep in your analysis into numerical attributes. For example you can keep the attributes `Age`, `Pclass`, `Sex` and `Embarked`. Please note that you need to transform `Sex` and `Embarked`. Of course you can do a lot more with the attributes, there are plenty of tutorials out there. Just keep it simple for the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Embarked feature takes `S`, `Q`, `C` values based on port of embarkation. The `embarked` feature has two missing values. We decide to fill those missing values with the most \n",
    "frequent port of embarkation. To find out, we use the `describe` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top value is `S`. We fill that in with the `fillna('S')` method (`df_train['Embarked'].fillna('S')`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do the same transformation for the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Preparing training and test data\n",
    "\n",
    "We will first extract the most relevant attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train dataset needs to be split into the feature and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test dataset does not provide the correct labels (the attribute `Survived`). When participating in the Kaggle competition, you are supposed to submit the prediction for the instances in the test dataset to the Kaggle Website. In order to be able to evaluate the applied method, we need to split the training dataset as done in the sample notebook into the training and test data.\n",
    "\n",
    "Please note that there are more elaborate methods to train and test datasets, for example cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Classification\n",
    "\n",
    "You can use the Decision Tree Classifier to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6: Evaluation\n",
    "\n",
    "You need to submit the test dataset to the Kaggle competition to get your score for the test dataset. If you want to evaluate it yourself, you need to use the split the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
